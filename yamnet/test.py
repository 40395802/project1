import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import sounddevice as sd
import librosa
import os
from sklearn.ensemble import IsolationForest
import joblib
from datetime import datetime

class AccidentSoundAnomalyDetector:
    def __init__(self):
        # YAMNet ëª¨ë¸ ë¡œë“œ
        self.yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')
        
        # Isolation Forest ëª¨ë¸ (ì´ìƒ ê°ì§€ìš©)
        self.anomaly_detector = IsolationForest(
            contamination=0.1,  # ì´ìƒì¹˜ ë¹„ìœ¨ ì˜ˆìƒê°’
            random_state=42,
            n_estimators=100
        )
        
        self.YAMNET_SAMPLE_RATE = 16000
        self.threshold = None  # ìë™ìœ¼ë¡œ ì„¤ì •ë  ì„ê³„ê°’
        
    def preprocess_audio(self, audio_path):
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ YAMNet ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        audio_data, sr = librosa.load(audio_path, sr=self.YAMNET_SAMPLE_RATE)
        
        # YAMNet ì„ë² ë”© ì¶”ì¶œ
        scores, embeddings, spectrogram = self.yamnet_model(audio_data)
        
        # ì„ë² ë”©ì˜ í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ë‹¨ì¼ ë²¡í„°ë¡œ ë³€í™˜
        embedding_mean = tf.reduce_mean(embeddings, axis=0)
        return embedding_mean.numpy()
    
    def train(self, accident_dir):
        """ì‚¬ê³ ìŒ ë°ì´í„°ë§Œìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ"""
        print("ì‚¬ê³ ìŒ ë°ì´í„° ë¡œë”© ì¤‘...")
        X = []  # ì„ë² ë”© íŠ¹ì§•
        
        # ì‚¬ê³ ìŒ íŒŒì¼ ì²˜ë¦¬
        for filename in os.listdir(accident_dir):
            if filename.endswith(('.wav', '.mp3')):
                audio_path = os.path.join(accident_dir, filename)
                embedding = self.preprocess_audio(audio_path)
                X.append(embedding)
        
        X = np.array(X)
        print(f"ì´ {len(X)}ê°œì˜ ì‚¬ê³ ìŒ ë°ì´í„°ë¡œ í•™ìŠµ")
        
        # Isolation Forest í•™ìŠµ
        print("ì´ìƒ ê°ì§€ ëª¨ë¸ í•™ìŠµ ì¤‘...")
        self.anomaly_detector.fit(X)
        
        # ì„ê³„ê°’ ì„¤ì •ì„ ìœ„í•œ ì ìˆ˜ ê³„ì‚°
        scores = self.anomaly_detector.score_samples(X)
        self.threshold = np.percentile(scores, 5)  # í•˜ìœ„ 5% ê¸°ì¤€ìœ¼ë¡œ ì„ê³„ê°’ ì„¤ì •
        
        # ëª¨ë¸ ì €ì¥
        model_path = 'accident_anomaly_detector.joblib'
        joblib.dump({'model': self.anomaly_detector, 'threshold': self.threshold}, model_path)
        print(f"ëª¨ë¸ ì €ì¥ë¨: {model_path}")
    
    def load_model(self, model_path='accident_anomaly_detector.joblib'):
        """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        saved_data = joblib.load(model_path)
        self.anomaly_detector = saved_data['model']
        self.threshold = saved_data['threshold']
    
    def predict_realtime(self, audio_data, input_sample_rate):
        """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë°ì´í„°ì—ì„œ ì‚¬ê³ ìŒ ê°ì§€"""
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì²˜ë¦¬
        if audio_data.ndim > 1:
            audio_data = np.mean(audio_data, axis=1)
        
        if input_sample_rate != self.YAMNET_SAMPLE_RATE:
            audio_data = librosa.resample(
                audio_data, 
                orig_sr=input_sample_rate, 
                target_sr=self.YAMNET_SAMPLE_RATE
            )
        
        # YAMNet ì„ë² ë”© ì¶”ì¶œ
        scores, embeddings, spectrogram = self.yamnet_model(audio_data)
        embedding_mean = tf.reduce_mean(embeddings, axis=0).numpy()
        
        # ì´ìƒ ê°ì§€ ì ìˆ˜ ê³„ì‚°
        anomaly_score = self.anomaly_detector.score_samples([embedding_mean])[0]
        
        # ì„ê³„ê°’ê³¼ ë¹„êµí•˜ì—¬ ì‚¬ê³ ìŒ ì—¬ë¶€ íŒë‹¨
        is_accident = anomaly_score < self.threshold
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (0~1 ë²”ìœ„ë¡œ ì •ê·œí™”)
        confidence = 1 - (anomaly_score - self.anomaly_detector.offset_) / (np.abs(self.threshold - self.anomaly_detector.offset_))
        confidence = np.clip(confidence, 0, 1)
        
        return is_accident, confidence

def start_monitoring(detector):
    """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
    SAMPLE_RATE = 48000
    DURATION = 1
    
    def audio_callback(indata, frames, time, status, detector):
        if status:
            print(status)
        
        audio_data = indata.copy()
        is_accident, confidence = detector.predict_realtime(audio_data, SAMPLE_RATE)
        
        # í˜„ì¬ ì‹œê°„
        current_time = datetime.now().strftime("%H:%M:%S")
        
        # ìƒíƒœ ì¶œë ¥
        if is_accident:
            print(f"\rğŸš¨ [{current_time}] ì‚¬ê³ ìŒ ê°ì§€! (ì‹ ë¢°ë„: {confidence:.1%})", end="")
        else:
            print(f"\râœ… [{current_time}] ì •ìƒ (ì‹ ë¢°ë„: {confidence:.1%})", end="")
    
    with sd.InputStream(
        callback=lambda *args: audio_callback(*args, detector),
        channels=1,
        samplerate=SAMPLE_RATE,
        blocksize=int(SAMPLE_RATE * DURATION)
    ):
        print("ì‚¬ê³ ìŒ ê°ì§€ ëª¨ë‹ˆí„°ë§ ì‹œì‘... (Ctrl+Cë¡œ ì¢…ë£Œ)")
        try:
            while True:
                pass
        except KeyboardInterrupt:
            print("\nëª¨ë‹ˆí„°ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

# ì‚¬ìš© ì˜ˆì‹œ:
"""
# ê°ì§€ê¸° ì´ˆê¸°í™”
detector = AccidentSoundAnomalyDetector()

# í•™ìŠµ (ì²˜ìŒ í•œ ë²ˆë§Œ)
detector.train("./dataset/accident/")

# ë˜ëŠ” ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
detector.load_model()

# ëª¨ë‹ˆí„°ë§ ì‹œì‘
start_monitoring(detector)
"""