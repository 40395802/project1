import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import sounddevice as sd
import librosa
import os
from sklearn.ensemble import IsolationForest
import joblib
from datetime import datetime
import matplotlib.pyplot as plt
from dataclasses import dataclass
from typing import Tuple, Optional
import logging
import yaml
import queue
from threading import Thread


@dataclass
class AudioConfig:
    """ì˜¤ë””ì˜¤ ì„¤ì • í´ë˜ìŠ¤"""
    sample_rate: int = 48000
    duration: int = 1
    channels: int = 1
    yamnet_sample_rate: int = 16000

@dataclass
class ModelConfig:
    """ëª¨ë¸ ì„¤ì • í´ë˜ìŠ¤"""
    contamination: float = 0.1
    n_estimators: int = 100
    threshold_percentile: int = 5
    model_path: str = 'accident_anomaly_detector.joblib'

class AudioBuffer:
    """ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì˜¤ë””ì˜¤ ë²„í¼"""
    def __init__(self, maxsize=10):
        self.buffer = queue.Queue(maxsize=maxsize)
    
    def put(self, data):
        try:
            self.buffer.put_nowait(data)
        except queue.Full:
            self.buffer.get()  # ê°€ì¥ ì˜¤ë˜ëœ ë°ì´í„° ì œê±°
            self.buffer.put(data)
    
    def get(self):
        return self.buffer.get() if not self.buffer.empty() else None

class AccidentSoundAnomalyDetector:
    def __init__(self, audio_config: AudioConfig = None, model_config: ModelConfig = None):
        """
        í–¥ìƒëœ ì´ˆê¸°í™” í•¨ìˆ˜
        """
        self.audio_config = audio_config or AudioConfig()
        self.model_config = model_config or ModelConfig()
        self.audio_buffer = AudioBuffer()
        
        # ë¡œê¹… ì„¤ì •
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        
        try:
            self.logger.info("YAMNet ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')
            
            self.anomaly_detector = IsolationForest(
                contamination=self.model_config.contamination,
                random_state=42,
                n_estimators=self.model_config.n_estimators
            )
            
            self.threshold = None
            
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def preprocess_audio(self, audio_data: np.ndarray, sr: int) -> np.ndarray:
        """
        ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ í•¨ìˆ˜
        """
        try:
            if audio_data.ndim > 1:
                audio_data = np.mean(audio_data, axis=1)
            
            if sr != self.audio_config.yamnet_sample_rate:
                audio_data = librosa.resample(
                    audio_data, 
                    orig_sr=sr,
                    target_sr=self.audio_config.yamnet_sample_rate
                )
            
            _, embeddings, _ = self.yamnet_model(audio_data)
            return tf.reduce_mean(embeddings, axis=0).numpy()
            
        except Exception as e:
            self.logger.error(f"ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise

    @property
    def is_model_ready(self) -> bool:
        """ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸"""
        return self.threshold is not None and self.anomaly_detector is not None

    def train(self, accident_dir: str) -> None:
        """
        í–¥ìƒëœ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
        """
        try:
            self.logger.info("ì‚¬ê³ ìŒ ë°ì´í„° ë¡œë”© ì¤‘...")
            X = []
            
            for filename in os.listdir(accident_dir):
                if filename.endswith(('.wav', '.mp3')):
                    audio_path = os.path.join(accident_dir, filename)
                    audio_data, sr = librosa.load(audio_path, sr=self.audio_config.yamnet_sample_rate)
                    embedding = self.preprocess_audio(audio_data, sr)
                    X.append(embedding)
            
            X = np.array(X)
            self.logger.info(f"ì´ {len(X)}ê°œì˜ ì‚¬ê³ ìŒ ë°ì´í„°ë¡œ í•™ìŠµ")
            
            self.anomaly_detector.fit(X)
            scores = self.anomaly_detector.score_samples(X)
            self.threshold = np.percentile(scores, self.model_config.threshold_percentile)
            
            self._save_model()
            
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise

    def _save_model(self) -> None:
        """ëª¨ë¸ ì €ì¥"""
        try:
            model_data = {
                'model': self.anomaly_detector,
                'threshold': self.threshold,
                'config': {
                    'audio': self.audio_config.__dict__,
                    'model': self.model_config.__dict__
                }
            }
            joblib.dump(model_data, self.model_config.model_path)
            self.logger.info(f"ëª¨ë¸ ì €ì¥ë¨: {self.model_config.model_path}")
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def load_model(self) -> None:
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            saved_data = joblib.load(self.model_config.model_path)
            self.anomaly_detector = saved_data['model']
            self.threshold = saved_data['threshold']
            
            # ì„¤ì • ë³µì›
            if 'config' in saved_data:
                self.audio_config = AudioConfig(**saved_data['config']['audio'])
                self.model_config = ModelConfig(**saved_data['config']['model'])
                
            self.logger.info("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def predict_realtime(self, audio_data: np.ndarray, input_sample_rate: int) -> Tuple[bool, float, float, np.ndarray, np.ndarray]:
        """
        ì‹¤ì‹œê°„ ì˜ˆì¸¡ í•¨ìˆ˜
        """
        try:
            if not self.is_model_ready:
                raise RuntimeError("ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµí•˜ê±°ë‚˜ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            
            embedding = self.preprocess_audio(audio_data, input_sample_rate)
            
            # ì´ìƒ ê°ì§€ ì ìˆ˜ ê³„ì‚°
            anomaly_score = self.anomaly_detector.score_samples([embedding])[0]
            if np.isnan(anomaly_score):
                anomaly_score = 0
            
            is_accident = anomaly_score < self.threshold
            confidence = np.clip((self.threshold - anomaly_score) / np.abs(self.threshold), 0, 1)
            similarity = np.clip(1 - np.abs(anomaly_score / self.threshold), 0, 1)
            
            mel_spectrogram = self.compute_log_mel_spectrogram(audio_data, input_sample_rate)
            
            return is_accident, confidence, similarity, mel_spectrogram, audio_data
            
        except Exception as e:
            self.logger.error(f"ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            raise

    def compute_log_mel_spectrogram(self, audio_data: np.ndarray, sample_rate: int) -> np.ndarray:
        """mel ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê³„ì‚°"""
        try:
            D = librosa.stft(audio_data)
            mel_spectrogram = librosa.feature.melspectrogram(
                S=np.abs(D), 
                sr=sample_rate, 
                n_mels=128
            )
            return librosa.power_to_db(mel_spectrogram)
        except Exception as e:
            self.logger.error(f"ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            raise

def plot_spectrogram_and_waveform(mel_spectrogram: np.ndarray, waveform: np.ndarray, sample_rate: int) -> None:
    """ì‹œê°í™” í•¨ìˆ˜"""
    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        ax1.plot(np.linspace(0, len(waveform) / sample_rate, len(waveform)), waveform)
        ax1.set_title("íŒŒí˜• (ì‹œê°„ ë„ë©”ì¸)")
        ax1.set_xlabel("ì‹œê°„ (ì´ˆ)")
        ax1.set_ylabel("ì§„í­")
        ax1.grid(True)
        
        img = ax2.imshow(
            mel_spectrogram, 
            aspect='auto', 
            origin='lower', 
            cmap='inferno',
            extent=[0, mel_spectrogram.shape[-1] / sample_rate, 0, sample_rate / 2]
        )
        ax2.set_title("ë¡œê·¸-ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨")
        ax2.set_xlabel("ì‹œê°„ (ì´ˆ)")
        ax2.set_ylabel("ì£¼íŒŒìˆ˜ (Hz)")
        fig.colorbar(img, ax=ax2, format="%+2.0f dB")
        ax2.grid(True)
        
        plt.tight_layout()
        plt.show()
        
    except Exception as e:
        logging.error(f"ì‹œê°í™” ì‹¤íŒ¨: {e}")
        raise

class AudioMonitor:
    """ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    def __init__(self, detector: AccidentSoundAnomalyDetector, config: AudioConfig):
        self.detector = detector
        self.config = config
        self.is_running = False
        self.logger = logging.getLogger(__name__)
    
    def audio_callback(self, indata: np.ndarray, frames: int, time, status) -> None:
        """ì˜¤ë””ì˜¤ ì½œë°± í•¨ìˆ˜"""
        if status:
            self.logger.warning(f"ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìƒíƒœ: {status}")
        
        try:
            audio_data = indata.copy()
            self.detector.audio_buffer.put({
                'data': audio_data,
                'timestamp': datetime.now()
            })
            
        except Exception as e:
            self.logger.error(f"ì˜¤ë””ì˜¤ ì½œë°± ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def process_audio(self) -> None:
        """ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
        while self.is_running:
            try:
                audio_packet = self.detector.audio_buffer.get()
                if audio_packet is None:
                    continue
                
                audio_data = audio_packet['data']
                timestamp = audio_packet['timestamp']
                
                results = self.detector.predict_realtime(
                    audio_data, 
                    self.config.sample_rate
                )
                
                is_accident, confidence, similarity, mel_spectrogram, waveform = results
                
                current_time = timestamp.strftime("%H:%M:%S")
                if is_accident:
                    print(f"\rğŸš¨ [{current_time}] ì‚¬ê³ ìŒ ê°ì§€! (ì‹ ë¢°ë„: {confidence:.1%}, ìœ ì‚¬ë„: {similarity:.1%})", end="")
                    plot_spectrogram_and_waveform(mel_spectrogram, waveform, self.config.sample_rate)
                else:
                    print(f"\râœ… [{current_time}] ì •ìƒ (ì‹ ë¢°ë„: {confidence:.1%}, ìœ ì‚¬ë„: {similarity:.1%})", end="")
                    
            except Exception as e:
                self.logger.error(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def start(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        try:
            self.is_running = True
            
            # ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
            process_thread = Thread(target=self.process_audio)
            process_thread.start()
            
            with sd.InputStream(
                callback=self.audio_callback,
                channels=self.config.channels,
                samplerate=self.config.sample_rate,
                blocksize=int(self.config.sample_rate * self.config.duration)
            ):
                print("ì‚¬ê³ ìŒ ê°ì§€ ëª¨ë‹ˆí„°ë§ ì‹œì‘... (Ctrl+Cë¡œ ì¢…ë£Œ)")
                try:
                    while self.is_running:
                        sd.sleep(1000)
                except KeyboardInterrupt:
                    self.stop()
                    
        except Exception as e:
            self.logger.error(f"ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨: {e}")
            self.stop()
            raise
    
